{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43fffefc-75c7-49dc-af64-a8211050ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188bc0ae-276b-4965-a9b4-124f9eb61acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b29b91e-d60d-4852-8863-81a0b099696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92878f1c-13bb-44af-832e-ca745704b771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#Check data size\n",
    "print(train_data.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1feeb5a5-4427-4418-a038-740c88a45e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.targets.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012dbc07-47b0-403a-b245-3ea7360a980e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(test_data.data[2])\n",
    "plt.title('%i' % test_data.targets[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4e9a200-f2a0-47f8-9a2b-9870f41811e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x2057a989b70>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x2057a989810>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Loading\n",
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "}\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7fd0115-be33-4d69-8c83-1c4bd2c14547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Neural Network\n",
    "import torch.nn as nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output, x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df641bd8-1e7c-4d5a-a0ce-aff0dc0a7036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "206dbbb1-80f3-4abf-90ef-6bec441aaac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize Loss Function\n",
    "loss_func = nn.CrossEntropyLoss()   \n",
    "loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "197fcbb4-a2c3-426c-ae7a-876fddba40c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize Optimizer\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.01)   \n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258de0dc-122e-48b5-8667-d278c9131879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/600], Loss: 0.2567\n",
      "Epoch [1/10], Step [200/600], Loss: 0.0792\n",
      "Epoch [1/10], Step [300/600], Loss: 0.0654\n",
      "Epoch [1/10], Step [400/600], Loss: 0.0906\n",
      "Epoch [1/10], Step [500/600], Loss: 0.0363\n",
      "Epoch [1/10], Step [600/600], Loss: 0.1892\n",
      "Epoch [2/10], Step [100/600], Loss: 0.0385\n",
      "Epoch [2/10], Step [200/600], Loss: 0.0367\n",
      "Epoch [2/10], Step [300/600], Loss: 0.0615\n",
      "Epoch [2/10], Step [400/600], Loss: 0.1002\n",
      "Epoch [2/10], Step [500/600], Loss: 0.0086\n",
      "Epoch [2/10], Step [600/600], Loss: 0.0373\n",
      "Epoch [3/10], Step [100/600], Loss: 0.0572\n",
      "Epoch [3/10], Step [200/600], Loss: 0.0268\n",
      "Epoch [3/10], Step [300/600], Loss: 0.1103\n",
      "Epoch [3/10], Step [400/600], Loss: 0.0513\n",
      "Epoch [3/10], Step [500/600], Loss: 0.0314\n",
      "Epoch [3/10], Step [600/600], Loss: 0.0822\n",
      "Epoch [4/10], Step [100/600], Loss: 0.0769\n",
      "Epoch [4/10], Step [200/600], Loss: 0.0814\n",
      "Epoch [4/10], Step [300/600], Loss: 0.0512\n",
      "Epoch [4/10], Step [400/600], Loss: 0.1142\n",
      "Epoch [4/10], Step [500/600], Loss: 0.0923\n",
      "Epoch [4/10], Step [600/600], Loss: 0.1397\n",
      "Epoch [5/10], Step [100/600], Loss: 0.1557\n",
      "Epoch [5/10], Step [200/600], Loss: 0.0577\n",
      "Epoch [5/10], Step [300/600], Loss: 0.0969\n",
      "Epoch [5/10], Step [400/600], Loss: 0.0751\n",
      "Epoch [5/10], Step [500/600], Loss: 0.0997\n",
      "Epoch [5/10], Step [600/600], Loss: 0.0743\n",
      "Epoch [6/10], Step [100/600], Loss: 0.0196\n",
      "Epoch [6/10], Step [200/600], Loss: 0.0110\n",
      "Epoch [6/10], Step [300/600], Loss: 0.0182\n",
      "Epoch [6/10], Step [400/600], Loss: 0.0552\n",
      "Epoch [6/10], Step [500/600], Loss: 0.0315\n",
      "Epoch [6/10], Step [600/600], Loss: 0.0599\n",
      "Epoch [7/10], Step [100/600], Loss: 0.0201\n",
      "Epoch [7/10], Step [200/600], Loss: 0.0063\n",
      "Epoch [7/10], Step [300/600], Loss: 0.0501\n",
      "Epoch [7/10], Step [400/600], Loss: 0.0819\n",
      "Epoch [7/10], Step [500/600], Loss: 0.0079\n",
      "Epoch [7/10], Step [600/600], Loss: 0.0400\n"
     ]
    }
   ],
   "source": [
    "#Training the Model\n",
    "from torch.autograd import Variable\n",
    "num_epochs = 10\n",
    "def train(num_epochs, cnn, loaders):\n",
    "    \n",
    "    cnn.train()\n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            \n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(images)   # batch x\n",
    "            b_y = Variable(labels)   # batch y\n",
    "            output = cnn(b_x)[0]               \n",
    "            loss = loss_func(output, b_y)\n",
    "            \n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()    \n",
    "            # apply gradients             \n",
    "            optimizer.step()                \n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "                pass\n",
    "        \n",
    "            pass\n",
    "    \n",
    "    \n",
    "        pass\n",
    "train(num_epochs, cnn, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38b489-4a2e-4e3e-bfe5-50cd9f673f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Accuracy\n",
    "def test():\n",
    "    # Test the model\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in loaders['test']:\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "            pass\n",
    "        print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
    "    \n",
    "    pass\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf8cdc8c-4c4f-4f20-a853-6bdc5147163d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 5, 7, 9, 6, 4, 9, 7, 3, 8], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(loaders['test']))\n",
    "imgs, lbls = sample\n",
    "actual_number = lbls[:10].numpy()\n",
    "actual_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a26f428-02f5-4daa-b541-f7105df5da61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction number: [9 5 7 9 6 4 9 7 3 8]\n",
      "Actual number: [9 5 7 9 6 4 9 7 3 8]\n"
     ]
    }
   ],
   "source": [
    "test_output, last_layer = cnn(imgs[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(f'Prediction number: {pred_y}')\n",
    "print(f'Actual number: {actual_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313becd0-d9a5-4e15-8a59-04f6689336c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
